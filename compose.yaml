services:
  backend:
    image: backend
    build:
      context: .
      dockerfile: ./Backend/Dockerfile
    
  deep_seek:
    build:
      context: ./DeepSeek
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1  # Ensures logs are streamed immediately
      - TRANSFORMERS_CACHE=/root/.cache/huggingface  # Explicitly set cache location
      - TRANSFORMERS_OFFLINE=0  # Allow online model fetching
    command: uvicorn deepseek_api:app --host 0.0.0.0 --port 8000 --reload --log-level info
    #volumes:
      #- ./DeepSeek/offload_folder:/app/offload_folder:rw  # Explicitly set read-write permissions
      #- ./DeepSeek/ai_images:/root/.cache/huggingface:rw  # Cache for model downloads
    networks:
      - my_network
networks:
  my_network:
    driver: bridge